#!/usr/bin/env python3
"""
Test Azure OpenAI integration with real credentials.

This script tests the Azure OpenAI integration using your actual resource.
"""

import os
import asyncio


async def test_azure_configuration():
    """Test Azure OpenAI with real configuration."""
    print("üîß Testing Azure OpenAI Configuration")
    print("=" * 50)

    # Set your Azure OpenAI configuration
    test_config = {
        "LLM_PROVIDER": "azure",
        "AZURE_OPENAI_API_KEY": "your-azure-openai-key-here",
        "AZURE_OPENAI_ENDPOINT": "https://your-resource.openai.azure.com/",
        "AZURE_OPENAI_API_VERSION": "2025-04-01-preview",
        "LLM_MODEL": "gpt-4.1"
    }

    # Save original environment
    original_env = dict(os.environ)

    try:
        # Clear existing LLM config
        for key in list(os.environ.keys()):
            if key.startswith(('LLM_', 'OPENAI_', 'AZURE_')):
                del os.environ[key]

        # Set test configuration
        for key, value in test_config.items():
            os.environ[key] = value

        # Reload modules
        import importlib
        import app.config
        importlib.reload(app.config)
        from app.config import settings
        from app.llm.client import LLMClient

        # Test client initialization
        print(f"   ‚úì Provider: {settings.llm_provider}")
        print(f"   ‚úì Endpoint: {settings.azure_openai_endpoint}")
        print(f"   ‚úì API Version: {settings.azure_openai_api_version}")
        print(f"   ‚úì Model: {settings.llm_default_model}")

        # Initialize client
        client = LLMClient()
        print(f"   ‚úì Client initialized successfully")
        print(f"   ‚úì Uses Responses API: {client.use_responses_api}")
        print(f"   ‚úì Active model: {client.active_model}")

        # Test configuration endpoint
        from app.routers.config import get_config
        config = await get_config()

        azure_features = config["providers"]["azure"]["features"]
        print(f"   ‚úì Responses API enabled: {azure_features['responses_api']}")
        print(f"   ‚úì Available API versions: {config['providers']['azure']['api_versions']}")

        # Test message conversion logic
        test_messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello!"}
        ]

        if client.use_responses_api:
            # Simulate message conversion from _complete_responses_api
            input_messages = []
            system_content = None

            for msg in test_messages:
                if msg["role"] == "system":
                    system_content = msg["content"]
                else:
                    input_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

            print(f"   ‚úì Message conversion: {len(test_messages)} ‚Üí {len(input_messages)} + system")
            print(f"   ‚úì System instructions: {system_content is not None}")

        print("\nüéâ Azure OpenAI configuration test passed!")
        print("\nüìù Your configuration is ready to use:")
        print("   LLM_PROVIDER=azure")
        print("   AZURE_OPENAI_API_KEY=your-azure-openai-key-here")
        print("   AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/")
        print("   AZURE_OPENAI_API_VERSION=2025-04-01-preview")
        print("   LLM_MODEL=gpt-4.1")

        return True

    except Exception as e:
        print(f"   ‚úó Configuration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # Restore original environment
        os.environ.clear()
        os.environ.update(original_env)


async def test_simple_completion():
    """Test a simple completion (without making actual API call)."""
    print("\nüí¨ Testing Completion Setup")
    print("=" * 50)

    # Set configuration again
    os.environ.update({
        "LLM_PROVIDER": "azure",
        "AZURE_OPENAI_API_KEY": "your-azure-openai-key-here",
        "AZURE_OPENAI_ENDPOINT": "https://your-resource.openai.azure.com/",
        "AZURE_OPENAI_API_VERSION": "2025-04-01-preview",
        "LLM_MODEL": "gpt-4.1"
    })

    try:
        import importlib
        import app.config
        importlib.reload(app.config)
        from app.llm.client import LLMClient

        client = LLMClient()

        # Test parameters for completion
        test_messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Say hello!"}
        ]

        print(f"   ‚úì Client ready for completions")
        print(f"   ‚úì Model: {client.active_model}")
        print(f"   ‚úì API type: {'Responses' if client.use_responses_api else 'Chat Completions'}")
        print(f"   ‚úì Test messages prepared: {len(test_messages)}")

        # Note: Not making actual API call to avoid costs during testing
        print("   ‚ÑπÔ∏è  Ready for real API calls (test skipped to avoid costs)")

        return True

    except Exception as e:
        print(f"   ‚úó Completion setup failed: {e}")
        return False


async def main():
    """Run all tests."""
    print("üöÄ Azure OpenAI Real Configuration Test")
    print("=" * 60)

    tests = [
        await test_azure_configuration(),
        await test_simple_completion(),
    ]

    passed = sum(tests)
    total = len(tests)

    print(f"\nüìä Test Results: {passed}/{total} tests passed")

    if passed == total:
        print("\n‚úÖ Your Azure OpenAI integration is ready!")
        print("\nTo activate:")
        print("1. Copy the configuration above to your .env file")
        print("2. Restart your backend server")
        print("3. Test via frontend or API endpoints")
        print("\n‚ö° Your deployment supports the latest Responses API with advanced features!")
    else:
        print(f"\n‚ùå {total - passed} tests failed")
        print("Please check the configuration and try again")


if __name__ == "__main__":
    asyncio.run(main())
