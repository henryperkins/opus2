#!/usr/bin/env python3
"""
Simplified Azure OpenAI integration test.

Tests the core functionality of the Azure OpenAI implementation.
"""

import asyncio


def test_basic_imports():
    """Test that all modules import correctly."""
    print("üì¶ Testing Basic Imports")
    print("=" * 40)

    try:
        # Test imports without assigning to variables
        __import__('app.config')
        __import__('app.llm.client')
        __import__('app.routers.config')
        print("   ‚úì All imports successful")
        return True
    except Exception as e:
        print(f"   ‚úó Import error: {e}")
        return False


def test_llm_client_initialization():
    """Test LLM client can be initialized with different providers."""
    print("\nüîß Testing LLM Client Initialization")
    print("=" * 40)

    # Test OpenAI provider (default)
    try:
        from app.llm.client import LLMClient
        client = LLMClient()
        print(f"   ‚úì Default provider: {client.provider}")
        print(f"   ‚úì Default model: {client.active_model}")
        print(f"   ‚úì Responses API: {client.use_responses_api}")
        return True
    except Exception as e:
        print(f"   ‚úó LLM client initialization error: {e}")
        return False


async def test_config_endpoint():
    """Test configuration endpoint returns expected structure."""
    print("\n‚öôÔ∏è  Testing Configuration Endpoint")
    print("=" * 40)

    try:
        from app.routers.config import get_config
        config = await get_config()

        # Basic structure checks
        assert "providers" in config
        assert "current" in config
        assert "openai" in config["providers"]
        assert "azure" in config["providers"]

        print("   ‚úì Config structure is valid")
        print(f"   ‚úì Providers: {list(config['providers'].keys())}")
        print(f"   ‚úì Current provider: {config['current']['provider']}")
        print(f"   ‚úì Current model: {config['current']['chat_model']}")

        # Azure-specific checks
        azure_config = config["providers"]["azure"]
        assert "chat_models" in azure_config
        assert "api_versions" in azure_config
        assert "features" in azure_config

        azure_models_count = len(azure_config['chat_models'])
        print(f"   ‚úì Azure models available: {azure_models_count}")
        print(f"   ‚úì Azure API versions: {azure_config['api_versions']}")

        return True
    except Exception as e:
        print(f"   ‚úó Config endpoint error: {e}")
        return False


def test_message_conversion_logic():
    """Test the message conversion logic for Responses API."""
    print("\nüîÑ Testing Message Conversion Logic")
    print("=" * 40)

    # Test messages
    chat_messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello, how are you?"},
        {"role": "assistant", "content": "I'm doing well, thank you!"},
        {"role": "user", "content": "Can you help me with coding?"}
    ]

    try:
        # Simulate the conversion logic from _complete_responses_api
        input_messages = []
        system_content = None

        for msg in chat_messages:
            if msg["role"] == "system":
                system_content = msg["content"]
            else:
                input_messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        # Validate conversion
        assert len(input_messages) == 3  # 4 original - 1 system = 3
        assert system_content == "You are a helpful assistant."
        assert input_messages[0]["role"] == "user"
        assert input_messages[1]["role"] == "assistant"
        assert input_messages[2]["role"] == "user"

        print(f"   ‚úì Original messages: {len(chat_messages)}")
        print(f"   ‚úì Converted input messages: {len(input_messages)}")
        system_extracted = system_content is not None
        print(f"   ‚úì System instructions extracted: {system_extracted}")
        print("   ‚úì Message conversion logic works correctly")

        return True
    except Exception as e:
        print(f"   ‚úó Message conversion test failed: {e}")
        return False


def test_azure_features():
    """Test Azure-specific feature detection."""
    print("\nüéØ Testing Azure Feature Detection")
    print("=" * 40)

    try:
        # Test API version detection
        test_cases = [
            ("2024-02-01", False),  # Standard API
            ("preview", True),      # Responses API
            ("2024-08-01", False),  # Standard API
        ]

        for api_version, expected_responses_api in test_cases:
            # Simulate the logic from LLMClient.__init__
            provider = "azure"
            use_responses_api = (
                provider == 'azure' and
                api_version == "preview"
            )

            expected_resp = expected_responses_api
            assert use_responses_api == expected_resp, \
                f"API version {api_version} should have " \
                f"responses_api={expected_resp}"

            print(f"   ‚úì API version {api_version}: "
                  f"responses_api={use_responses_api}")

        # Test authentication method detection
        has_azure_identity = True  # We know it's installed
        auth_methods = ["api_key", "entra_id"]

        for method in auth_methods:
            available = True  # Default to True
            if method == "api_key":
                # Always available
                available = True
            elif method == "entra_id":
                # Requires azure-identity package
                available = has_azure_identity

            print(f"   ‚úì Auth method {method}: available={available}")

        return True
    except Exception as e:
        print(f"   ‚úó Azure feature detection error: {e}")
        return False


async def main():
    """Run all tests."""
    print("üöÄ Azure OpenAI Integration Test Suite (Simplified)")
    print("=" * 60)

    tests = [
        test_basic_imports(),
        test_llm_client_initialization(),
        await test_config_endpoint(),
        test_message_conversion_logic(),
        test_azure_features(),
    ]

    passed = sum(tests)
    total = len(tests)

    print(f"\nüìä Test Results: {passed}/{total} tests passed")

    if passed == total:
        print("üéâ All tests passed!")
        print("\n‚úÖ Azure OpenAI integration is working correctly")
        print("\nNext steps:")
        print("1. Set up your Azure OpenAI resource")
        print("2. Configure environment variables in .env:")
        print("   - LLM_PROVIDER=azure")
        print("   - AZURE_OPENAI_API_KEY=your-key")
        azure_endpoint = "https://your-resource.openai.azure.com"
        print(f"   - AZURE_OPENAI_ENDPOINT={azure_endpoint}")
        print("   - AZURE_OPENAI_API_VERSION=preview  # For Responses API")
        print("3. Start the backend server")
        print("4. Test chat completions via the frontend or API")
    else:
        print(f"‚ùå {total - passed} tests failed")
        print("Please check the error messages above")


if __name__ == "__main__":
    asyncio.run(main())
